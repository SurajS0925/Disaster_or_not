# -*- coding: utf-8 -*-
"""Disasteer_or_not.ipynb

Automatically generated by Colab.

Original file is located at
    https://colab.research.google.com/drive/1JCBKULgPW2BASNKBcrq-zXWZJMb1tOAM
"""

import pandas as pd
import matplotlib.pyplot as plt
import seaborn as sns
from sklearn.model_selection import train_test_split
from sklearn.ensemble import RandomForestClassifier
from sklearn.metrics import accuracy_score
from sklearn.preprocessing import LabelEncoder

train_data_path = "/content/train.csv"
test_data_path = "/content/test.csv"

train_data = pd.read_csv(train_data_path)
test_data = pd.read_csv(test_data_path)

train_data

print(train_data.describe())

print(train_data.info())

print(train_data.head())

plt.figure(figsize = (10, 6))
sns.countplot(x ='disaster', data = train_data)
plt.title('Distribution of Disaster vs Non-Disaster Tweets')
plt.xlabel('Target')
plt.ylabel('Count')
plt.show()

plt.figure(figsize = (10, 6))
train_data['tweet_length'] = train_data['tweet'].apply(len)
sns.histplot(train_data['tweet_length'], bins=30, kde=False)
plt.title('Distribution of Tweet Lengths')
plt.xlabel('Number of Characters')
plt.ylabel('Count')
plt.show()

plt.figure(figsize = (10, 6))
top_keywords = train_data['keyword'].value_counts().head(10)
sns.barplot(x=top_keywords.values, y=top_keywords.index, palette='viridis')
plt.title('Top 10 Keywords in Tweets')
plt.xlabel('Count')
plt.ylabel('Keyword')
plt.show()

train_data.fillna('', inplace=True)
test_data.fillna('', inplace=True)

combined_data = pd.concat([train_data, test_data], axis=0)
combined_data

label_encoders = {}
for column in ['keyword','place']:
    le = LabelEncoder()
    le.fit(combined_data[column].astype(str).unique())
    train_data[column] = le.transform(train_data[column].astype(str))
    test_data[column] = le.transform(test_data[column].astype(str))
    label_encoders[column] = le

X_train = train_data.drop(columns=['id', 'tweet', 'disaster', 'tweet_length'])
y_train = train_data['disaster']
test_features = test_data.drop(columns=['id', 'tweet'])

clf = RandomForestClassifier(n_estimators=100, random_state=42)
clf.fit(X_train, y_train)

y_pred = clf.predict(X_train)
accuracy = accuracy_score(y_train, y_pred)
print(f'Training Accuracy: {accuracy:.2f}')

test_preds = clf.predict(test_features)

submission_data = pd.DataFrame({'id': test_data['id'], 'target': test_preds})

submission_data

plt.figure(figsize = (10, 6))
sns.countplot(x='target', data = submission_data)
plt.title('Distribution of Disaster vs Non-Disaster Tweets')
plt.xlabel('Target')
plt.ylabel('Count')
plt.show()

submission_data.to_csv('submission.csv', index=False)

